{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datacompy\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# narzedzia\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split,\n",
    "    cross_val_score,\n",
    "    cross_val_predict,\n",
    "    learning_curve,\n",
    "    RepeatedStratifiedKFold,\n",
    "    GridSearchCV\n",
    ")\n",
    "from collections import Counter\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn import tree\n",
    "from sklearn.tree import plot_tree\n",
    "\n",
    "# modele + Smote\n",
    "from xgboost import XGBClassifier, XGBRFClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from imblearn.over_sampling import SMOTE, BorderlineSMOTE\n",
    "from imblearn.under_sampling import NearMiss, RandomUnderSampler\n",
    "from ctgan import CTGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['is_private', 'is_failure', 'is_root', 'is_valid', 'not_valid_count',\n",
      "       'ip_failure', 'ip_success', 'no_failure', 'first', 'td', 'target'],\n",
      "      dtype='object')\n",
      "Klasyfikator: target\n",
      "0    41\n",
      "1    14\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"D:/ml/xgboost-main/data/ssh_logs/SSH.csv\")\n",
    "df = df.drop(columns=[\"user\", \"ts\"])\n",
    "print(df.columns)\n",
    "df.head()\n",
    "df = df.drop_duplicates()\n",
    "df.shape\n",
    "y = df[\"target\"]\n",
    "X = df.drop(columns=[\"target\"])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "df_data = df.copy()\n",
    "dell = pd.concat([X_test, y_test], axis=1)      #polaczenie macierzy X_test oraz y_test\n",
    "#print(dell.shape)                              #271-55=216\n",
    "target_num = dell['target'].value_counts()\n",
    "print(f'Klasyfikator: {target_num}')\n",
    "df_cleaned = df_data.merge(dell, how='left', indicator=True)            # Dodaje kolumnę '_merge' dla identyfikacji\n",
    "df_cleaned = df_cleaned[df_cleaned['_merge'] == 'left_only'].drop('_merge', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "     is_private  is_failure  is_root  is_valid  not_valid_count  ip_failure  \\\n",
      "0             1           1        0         1                0           1   \n",
      "1             1           1        0         1                0           2   \n",
      "2             1           0        0         1                0           0   \n",
      "3             1           1        0         1                0           1   \n",
      "4             1           1        0         1                0           2   \n",
      "..          ...         ...      ...       ...              ...         ...   \n",
      "105           1           1        0         1               20          14   \n",
      "106           1           1        0         1                5          26   \n",
      "107           0           1        1         0                8          30   \n",
      "108           1           1        1         0               28           8   \n",
      "109           1           1        0         0               29          38   \n",
      "\n",
      "     ip_success  no_failure  first   td  target    source  \n",
      "0             0           2      1    0       0  original  \n",
      "1             0           3      0   18       0  original  \n",
      "2             1           0      0  133       0  original  \n",
      "3             1           2      0   58       0  original  \n",
      "4             1           3      0   29       0  original  \n",
      "..          ...         ...    ...  ...     ...       ...  \n",
      "105           2          25      0   21       1       gan  \n",
      "106           2          12      0    0       1       gan  \n",
      "107           2          39      0    6       1       gan  \n",
      "108           2           8      0   42       1       gan  \n",
      "109           1           9      0   30       1       gan  \n",
      "\n",
      "[506 rows x 12 columns]\n",
      "Klasyfikatory: target\n",
      "1    342\n",
      "0    164\n",
      "Name: count, dtype: int64\n",
      "Kolumny:\n",
      " Index(['is_private', 'is_failure', 'is_root', 'is_valid', 'not_valid_count',\n",
      "       'ip_failure', 'ip_success', 'no_failure', 'first', 'td', 'target',\n",
      "       'source'],\n",
      "      dtype='object')\n",
      "Rozkład przed undersamplingiem: [164 342]\n",
      "Rozkład po undersamplingu: [164 164]\n"
     ]
    }
   ],
   "source": [
    "# concat all datasets\n",
    "file_path4 = \"D:\\\\ml\\\\xgboost-main\\\\data\\\\processed\\\\generated_data_test.csv\"        #sciezka wraz z nazwa pod jaka wygenerowac plik\n",
    "#df_cleaned = pd.read_csv()\n",
    "smote_data = pd.read_csv(\"D:\\\\ml\\\\xgboost-main\\\\data\\\\generated\\\\smote_data.csv\")\n",
    "boarderline_smote_data = pd.read_csv(\"D:\\\\ml\\\\xgboost-main\\\\data\\\\generated\\\\boarderlinesmote_data.csv\")\n",
    "gan_data = pd.read_csv(\"D:\\\\ml\\\\xgboost-main\\\\data\\\\generated\\\\GAN_data.csv\")\n",
    "\n",
    "data1 = pd.concat([df_cleaned, smote_data])\n",
    "data1['source'] = ['original' if i < len(df_cleaned) else 'smote' for i in range(len(data1))]\n",
    "data2 = pd.concat([boarderline_smote_data, gan_data])\n",
    "data2['source'] = ['boarderline' if i < len(boarderline_smote_data) else 'gan' for i in range(len(data2))]\n",
    "data = pd.concat([data1, data2])\n",
    "data = data.drop_duplicates()\n",
    "num_duplicates = data.duplicated().sum()\n",
    "print(num_duplicates)\n",
    "print(data)\n",
    "#data.to_csv(file_path4,index=False)\n",
    "target_num = data['target'].value_counts()\n",
    "print(f'Klasyfikatory: {target_num}')\n",
    "columns_list = data.columns\n",
    "print('Kolumny:\\n',columns_list)\n",
    "\n",
    "y_under = data['target']\n",
    "X_under = data.loc[:, ['is_private', 'is_failure', 'is_root', 'is_valid', 'not_valid_count',\n",
    "       'ip_failure', 'ip_success', 'no_failure', 'first', 'td']]\n",
    "\n",
    "\n",
    "RUS = RandomUnderSampler(random_state=42)\n",
    "X_resampled, y_resampled = RUS.fit_resample(X_under, y_under)\n",
    "\n",
    "print(\"Rozkład przed undersamplingiem:\", np.bincount(y_under))\n",
    "print(\"Rozkład po undersamplingu:\", np.bincount(y_resampled))\n",
    "\n",
    "#dodanie danych tak zeby bylo wiadomo skad pochodza, potem wylaczenie ostatniej kokumny przed undersamplingiem \n",
    "#i sprawdzenie % jaki wychodzi wspolczynnik wykorzystanych danych do najoptymalniejszej nauki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cal = pd.concat([X_resampled, y_resampled], axis=1)\n",
    "data_duplicate = data.copy()\n",
    "data_duplicate = data_duplicate.drop_duplicates()\n",
    "df_cal = pd.DataFrame(columns=data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liczba wierszy w data_duplicate: 506\n",
      "     is_private  is_failure  is_root  is_valid  not_valid_count  ip_failure  \\\n",
      "0             1           1        0         1                0           1   \n",
      "1             1           1        0         1                0           2   \n",
      "2             1           0        0         1                0           0   \n",
      "3             1           1        0         1                0           1   \n",
      "4             1           1        0         1                0           2   \n",
      "..          ...         ...      ...       ...              ...         ...   \n",
      "322           1           1        1         0               13          29   \n",
      "323           1           1        0         0               28          38   \n",
      "324           0           1        0         1                0           5   \n",
      "325           1           1        0         1               11          33   \n",
      "327           1           1        0         0               14          45   \n",
      "\n",
      "     ip_success  no_failure  first    td  target source     _merge  \n",
      "0             0           2      1     0       0    NaN  left_only  \n",
      "1             0           3      0    18       0    NaN  left_only  \n",
      "2             1           0      0   133       0    NaN  left_only  \n",
      "3             1           2      0    58       0    NaN  left_only  \n",
      "4             1           3      0    29       0    NaN  left_only  \n",
      "..          ...         ...    ...   ...     ...    ...        ...  \n",
      "322           0          45      0     8       1    NaN  left_only  \n",
      "323           0          36      0     6       1    NaN  left_only  \n",
      "324           0           8      0    37       1    NaN  left_only  \n",
      "325           2           9      0  1351       1    NaN  left_only  \n",
      "327           0          45      0     8       1    NaN  left_only  \n",
      "\n",
      "[320 rows x 13 columns]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot handle a non-unique multi-index!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[57], line 30\u001b[0m\n\u001b[0;32m     27\u001b[0m unique_data_cal_indexed \u001b[38;5;241m=\u001b[39m unique_data_cal\u001b[38;5;241m.\u001b[39mset_index([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis_private\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis_failure\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis_root\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Aktualizacja kolumny 'source' w unique_data_cal\u001b[39;00m\n\u001b[1;32m---> 30\u001b[0m \u001b[43munique_data_cal_indexed\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msource\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_duplicate_indexed\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msource\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Reset indeksu, aby zachować oryginalną strukturę\u001b[39;00m\n\u001b[0;32m     33\u001b[0m unique_data_cal \u001b[38;5;241m=\u001b[39m unique_data_cal_indexed\u001b[38;5;241m.\u001b[39mreset_index()\n",
      "File \u001b[1;32mc:\\Users\\mateu\\anaconda3\\envs\\python8\\lib\\site-packages\\pandas\\core\\series.py:3416\u001b[0m, in \u001b[0;36mSeries.update\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m   3413\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(other, Series):\n\u001b[0;32m   3414\u001b[0m     other \u001b[38;5;241m=\u001b[39m Series(other)\n\u001b[1;32m-> 3416\u001b[0m other \u001b[38;5;241m=\u001b[39m \u001b[43mother\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreindex_like\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3417\u001b[0m mask \u001b[38;5;241m=\u001b[39m notna(other)\n\u001b[0;32m   3419\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mputmask(mask\u001b[38;5;241m=\u001b[39mmask, new\u001b[38;5;241m=\u001b[39mother)\n",
      "File \u001b[1;32mc:\\Users\\mateu\\anaconda3\\envs\\python8\\lib\\site-packages\\pandas\\core\\generic.py:4474\u001b[0m, in \u001b[0;36mNDFrame.reindex_like\u001b[1;34m(self, other, method, copy, limit, tolerance)\u001b[0m\n\u001b[0;32m   4373\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4374\u001b[0m \u001b[38;5;124;03mReturn an object with matching indices as other object.\u001b[39;00m\n\u001b[0;32m   4375\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4464\u001b[0m \u001b[38;5;124;03m2014-02-15          35.1              NaN    medium\u001b[39;00m\n\u001b[0;32m   4465\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4466\u001b[0m d \u001b[38;5;241m=\u001b[39m other\u001b[38;5;241m.\u001b[39m_construct_axes_dict(\n\u001b[0;32m   4467\u001b[0m     axes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_AXIS_ORDERS,\n\u001b[0;32m   4468\u001b[0m     method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4471\u001b[0m     tolerance\u001b[38;5;241m=\u001b[39mtolerance,\n\u001b[0;32m   4472\u001b[0m )\n\u001b[1;32m-> 4474\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreindex\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43md\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\mateu\\anaconda3\\envs\\python8\\lib\\site-packages\\pandas\\core\\series.py:4918\u001b[0m, in \u001b[0;36mSeries.reindex\u001b[1;34m(self, index, axis, method, copy, level, fill_value, limit, tolerance)\u001b[0m\n\u001b[0;32m   4901\u001b[0m \u001b[38;5;129m@doc\u001b[39m(\n\u001b[0;32m   4902\u001b[0m     NDFrame\u001b[38;5;241m.\u001b[39mreindex,  \u001b[38;5;66;03m# type: ignore[has-type]\u001b[39;00m\n\u001b[0;32m   4903\u001b[0m     klass\u001b[38;5;241m=\u001b[39m_shared_doc_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mklass\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4916\u001b[0m     tolerance\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   4917\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Series:\n\u001b[1;32m-> 4918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreindex\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4920\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4922\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4924\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4925\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtolerance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4926\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\mateu\\anaconda3\\envs\\python8\\lib\\site-packages\\pandas\\core\\generic.py:5360\u001b[0m, in \u001b[0;36mNDFrame.reindex\u001b[1;34m(self, labels, index, columns, axis, method, copy, level, fill_value, limit, tolerance)\u001b[0m\n\u001b[0;32m   5357\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_multi(axes, copy, fill_value)\n\u001b[0;32m   5359\u001b[0m \u001b[38;5;66;03m# perform the reindex on the axes\u001b[39;00m\n\u001b[1;32m-> 5360\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reindex_axes\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   5361\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\n\u001b[0;32m   5362\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreindex\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\mateu\\anaconda3\\envs\\python8\\lib\\site-packages\\pandas\\core\\generic.py:5375\u001b[0m, in \u001b[0;36mNDFrame._reindex_axes\u001b[1;34m(self, axes, level, limit, tolerance, method, fill_value, copy)\u001b[0m\n\u001b[0;32m   5372\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   5374\u001b[0m ax \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_axis(a)\n\u001b[1;32m-> 5375\u001b[0m new_index, indexer \u001b[38;5;241m=\u001b[39m \u001b[43max\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreindex\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   5376\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtolerance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\n\u001b[0;32m   5377\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5379\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_axis_number(a)\n\u001b[0;32m   5380\u001b[0m obj \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_reindex_with_indexers(\n\u001b[0;32m   5381\u001b[0m     {axis: [new_index, indexer]},\n\u001b[0;32m   5382\u001b[0m     fill_value\u001b[38;5;241m=\u001b[39mfill_value,\n\u001b[0;32m   5383\u001b[0m     copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[0;32m   5384\u001b[0m     allow_dups\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   5385\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\mateu\\anaconda3\\envs\\python8\\lib\\site-packages\\pandas\\core\\indexes\\base.py:4272\u001b[0m, in \u001b[0;36mIndex.reindex\u001b[1;34m(self, target, method, level, limit, tolerance)\u001b[0m\n\u001b[0;32m   4268\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_indexer(\n\u001b[0;32m   4269\u001b[0m         target, method\u001b[38;5;241m=\u001b[39mmethod, limit\u001b[38;5;241m=\u001b[39mlimit, tolerance\u001b[38;5;241m=\u001b[39mtolerance\n\u001b[0;32m   4270\u001b[0m     )\n\u001b[0;32m   4271\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_multi:\n\u001b[1;32m-> 4272\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot handle a non-unique multi-index!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   4273\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_unique:\n\u001b[0;32m   4274\u001b[0m     \u001b[38;5;66;03m# GH#42568\u001b[39;00m\n\u001b[0;32m   4275\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot reindex on an axis with duplicate labels\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: cannot handle a non-unique multi-index!"
     ]
    }
   ],
   "source": [
    "# Łączenie danych z oznaczeniem, skąd pochodzą wiersze\n",
    "#df_cal = pd.concat([df_cal, data_duplicate[\"source\"]])\n",
    "\"\"\" df_cal = pd.merge(\n",
    "    df_cal,\n",
    "    data_duplicate[['source']],  # Wyciągamy tylko kolumnę 'source' z data_duplicate\n",
    "    how='inner'\n",
    "    )\n",
    "\n",
    "\"\"\"\n",
    "print(\"Liczba wierszy w data_duplicate:\", len(data_duplicate))\n",
    "\n",
    "#print(\"Liczba wierszy po merge:\", len(df_cal))\n",
    "#print(df_cal) \n",
    "unique_data_cal = pd.merge(data_cal, data_duplicate, how=\"inner\")\n",
    "#unique_data_cal = unique_data_cal.drop_duplicates()\n",
    "#print(unique_data_cal['source'].isnull().sum())  # Sprawdzenie braków\n",
    "unique_data_cal = pd.merge(data_cal, df_cal, how='outer', indicator=True)\n",
    "unique_data_cal = unique_data_cal.drop_duplicates()\n",
    "\n",
    "# Filtrowanie wierszy występujących tylko w `data_cal`\n",
    "print(unique_data_cal)\n",
    "\n",
    "#print(\"Liczba wierszy w data_cal:\", len())\n",
    "# Dopasowanie na podstawie indeksów (lub wspólnych kolumn)\n",
    "data_duplicate_indexed = data_duplicate.set_index(['is_private', 'is_failure', 'is_root', 'target'])\n",
    "\n",
    "unique_data_cal_indexed = unique_data_cal.set_index(['is_private', 'is_failure', 'is_root', 'target'])\n",
    "\n",
    "# Aktualizacja kolumny 'source' w unique_data_cal\n",
    "unique_data_cal_indexed['source'].update(data_duplicate_indexed['source'])\n",
    "\n",
    "# Reset indeksu, aby zachować oryginalną strukturę\n",
    "unique_data_cal = unique_data_cal_indexed.reset_index()\n",
    "\n",
    "print(\"Zaktualizowany unique_data_cal:\")\n",
    "print(unique_data_cal)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
